---
layout: post
title: "On AI"
tagline: "Test"
description: "Revised personal thinking on AI."
category: Fiction
tags: [fiction, AI, Watson, IBM, evolution]
---
{% include JB/setup %}
I just read a rather compelling piece about IBM's Watson and how 'he' was able to defeat two returning Jeopardy champions. As the article describes Watson is programmed to filter unstructured data, come up with a series of possible responses, then score each possible response to determine if any of the top responses are likely to be the correct response. If none of the top responses are deemed possible correct responses Watson will not risk an answer. The author of the article posed the question if Watson's performance was proof that we would be close to true AI anytime soon, and rhetorically answered that he did not know but was sure that it meant today AI could provide possible responses to a question posed in plain spoken language and discuss with the questioner the possible merits of each response. This has me thinking along the lines of what AI is thought of today as an ideal, and what AI will evolve into tomorrow as a reality. We tend to make our own reality, really. Today we interact with voice response systems as a form of infant AI, as time goes by and these systems increase in sophistication we will perhaps evolve our view of what AI is and in essence there will be a meeting in the middle. So while today we may have a view of AI as HAL defeating Frank in a game of chess, tomorrow our view of AI may be an conversation with a machine where the possibilities are debated, with the end result being the human in the conversation drawing whatever conclusion he thinks best.
